{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                 link  \\\nDe energiemarkt en salderen: hoe komt de prijsv...  https://radar.avrotros.nl/forum/energie-f51/de...   \nWoningen met verkeerde energielabels, wie heeft...  https://radar.avrotros.nl/forum/energie-f51/wo...   \nGreenchoice beoordelingen ...                       https://radar.avrotros.nl/forum/energie-f51/gr...   \nslimme meter meet niet altijd correct               https://radar.avrotros.nl/forum/energie-f51/sl...   \nEnergieleverancier kiezen met zonnepanelen          https://radar.avrotros.nl/forum/energie-f51/en...   \n...                                                                                               ...   \nEen energiecontract zonder mijn toestemming?        https://radar.avrotros.nl/forum/energie-f51/ee...   \nVattenfall wil Warmtelink plaatsen voor digitaa...  https://radar.avrotros.nl/forum/energie-f51/va...   \nEnergierekening opsplitsen in Netbeheer en Leve...  https://radar.avrotros.nl/forum/energie-f51/en...   \nFaillisement Energie Welkom: wat kan / mag ik?      https://radar.avrotros.nl/forum/energie-f51/fa...   \nNa failliete Welkom Energie nu de rekening van ...  https://radar.avrotros.nl/forum/energie-f51/na...   \n\n                                                                 date    code  \\\nDe energiemarkt en salderen: hoe komt de prijsv...  22 okt 2021 14:18  197725   \nWoningen met verkeerde energielabels, wie heeft...  13 feb 2023 19:48  200283   \nGreenchoice beoordelingen ...                       03 feb 2023 17:18  200199   \nslimme meter meet niet altijd correct               14 feb 2023 11:37  200287   \nEnergieleverancier kiezen met zonnepanelen          05 jan 2021 16:57  195768   \n...                                                               ...     ...   \nEen energiecontract zonder mijn toestemming?        09 mei 2022 17:04  198866   \nVattenfall wil Warmtelink plaatsen voor digitaa...  02 jun 2021 17:18  196961   \nEnergierekening opsplitsen in Netbeheer en Leve...  03 mar 2022 09:41  198540   \nFaillisement Energie Welkom: wat kan / mag ik?      15 nov 2021 09:41  197882   \nNa failliete Welkom Energie nu de rekening van ...  17 dec 2021 13:29  198056   \n\n                                                    reactions  \nDe energiemarkt en salderen: hoe komt de prijsv...         48  \nWoningen met verkeerde energielabels, wie heeft...         74  \nGreenchoice beoordelingen ...                              30  \nslimme meter meet niet altijd correct                       3  \nEnergieleverancier kiezen met zonnepanelen                100  \n...                                                       ...  \nEen energiecontract zonder mijn toestemming?                6  \nVattenfall wil Warmtelink plaatsen voor digitaa...         47  \nEnergierekening opsplitsen in Netbeheer en Leve...         17  \nFaillisement Energie Welkom: wat kan / mag ik?             31  \nNa failliete Welkom Energie nu de rekening van ...        176  \n\n[100 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>link</th>\n      <th>date</th>\n      <th>code</th>\n      <th>reactions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>De energiemarkt en salderen: hoe komt de prijsvorming tot stand?</th>\n      <td>https://radar.avrotros.nl/forum/energie-f51/de...</td>\n      <td>22 okt 2021 14:18</td>\n      <td>197725</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>Woningen met verkeerde energielabels, wie heeft daar ervaring mee?</th>\n      <td>https://radar.avrotros.nl/forum/energie-f51/wo...</td>\n      <td>13 feb 2023 19:48</td>\n      <td>200283</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>Greenchoice beoordelingen ...</th>\n      <td>https://radar.avrotros.nl/forum/energie-f51/gr...</td>\n      <td>03 feb 2023 17:18</td>\n      <td>200199</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>slimme meter meet niet altijd correct</th>\n      <td>https://radar.avrotros.nl/forum/energie-f51/sl...</td>\n      <td>14 feb 2023 11:37</td>\n      <td>200287</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>Energieleverancier kiezen met zonnepanelen</th>\n      <td>https://radar.avrotros.nl/forum/energie-f51/en...</td>\n      <td>05 jan 2021 16:57</td>\n      <td>195768</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Een energiecontract zonder mijn toestemming?</th>\n      <td>https://radar.avrotros.nl/forum/energie-f51/ee...</td>\n      <td>09 mei 2022 17:04</td>\n      <td>198866</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>Vattenfall wil Warmtelink plaatsen voor digitaal uitlezen verbruik</th>\n      <td>https://radar.avrotros.nl/forum/energie-f51/va...</td>\n      <td>02 jun 2021 17:18</td>\n      <td>196961</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>Energierekening opsplitsen in Netbeheer en Levering</th>\n      <td>https://radar.avrotros.nl/forum/energie-f51/en...</td>\n      <td>03 mar 2022 09:41</td>\n      <td>198540</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>Faillisement Energie Welkom: wat kan / mag ik?</th>\n      <td>https://radar.avrotros.nl/forum/energie-f51/fa...</td>\n      <td>15 nov 2021 09:41</td>\n      <td>197882</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>Na failliete Welkom Energie nu de rekening van Eneco voor november, wat nu?</th>\n      <td>https://radar.avrotros.nl/forum/energie-f51/na...</td>\n      <td>17 dec 2021 13:29</td>\n      <td>198056</td>\n      <td>176</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Web scraping from the radar AvroTros website\n",
    "search_link = \"https://radar.avrotros.nl/forum/energie-f51/index-s\"\n",
    "\n",
    "forum_url = BeautifulSoup(requests.get(search_link).content, 'html.parser')\n",
    "\n",
    "page_index = 0\n",
    "\n",
    "dict_topics = {}\n",
    "\n",
    "for i in range(0, 100, 25):\n",
    "    page_index = i\n",
    "\n",
    "    forum_url = BeautifulSoup(requests.get(search_link + str(page_index) + '.html').content, 'html.parser')\n",
    "\n",
    "    items = forum_url.find_all(class_=lambda x: x and x.startswith(\"row bg\"))\n",
    "\n",
    "    for item in items:\n",
    "        title = item.find('a', class_='topictitle')\n",
    "        topic_title = title.text\n",
    "\n",
    "        topic_link = \"https://radar.avrotros.nl/forum\" + \"/\" + title['href'].lstrip('./..').split('.html')[0] + '.html'\n",
    "\n",
    "        date_element = item.find(\"div\", class_=\"topic-poster responsive-hide left-box\").find(\"time\")\n",
    "        date = date_element.text\n",
    "\n",
    "        code_link = topic_link[-11:]\n",
    "        code = code_link[:6]\n",
    "\n",
    "        reactions_element = item.find(\"dd\", class_=\"posts\")\n",
    "        reactions = reactions_element.text\n",
    "        # Remove the 'Reacties' text\n",
    "        reactions = reactions[:-9]\n",
    "        reactions = int(reactions)\n",
    "\n",
    "        dict_topics[topic_title] = topic_link, date, code, reactions\n",
    "\n",
    "# Convert dict to dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df_topics = pd.DataFrame.from_dict(dict_topics, orient='index', columns=['link', 'date', 'code', 'reactions'])\n",
    "\n",
    "df_topics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://radar.avrotros.nl/forum/viewtopic.php?t=197725&start=0\n",
      "https://radar.avrotros.nl/forum/viewtopic.php?t=197725&start=20\n",
      "https://radar.avrotros.nl/forum/viewtopic.php?t=197725&start=40\n",
      "https://radar.avrotros.nl/forum/viewtopic.php?t=200283&start=0\n",
      "https://radar.avrotros.nl/forum/viewtopic.php?t=200283&start=20\n",
      "https://radar.avrotros.nl/forum/viewtopic.php?t=200283&start=40\n",
      "https://radar.avrotros.nl/forum/viewtopic.php?t=200283&start=60\n",
      "2021-10-22 14:32:00\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 topic  \\\n1    De energiemarkt en salderen: hoe komt de prijs...   \n2    De energiemarkt en salderen: hoe komt de prijs...   \n3    De energiemarkt en salderen: hoe komt de prijs...   \n4    De energiemarkt en salderen: hoe komt de prijs...   \n5    De energiemarkt en salderen: hoe komt de prijs...   \n..                                                 ...   \n120  Woningen met verkeerde energielabels, wie heef...   \n121  Woningen met verkeerde energielabels, wie heef...   \n122  Woningen met verkeerde energielabels, wie heef...   \n123  Woningen met verkeerde energielabels, wie heef...   \n124  Woningen met verkeerde energielabels, wie heef...   \n\n                                               content                date  \n1    Goedendag,In navolging van het inmiddels geslo... 2021-10-22 14:18:00  \n2    3.U verbruikt en produceert stroomDezelfde pri... 2021-10-22 14:52:00  \n3                               Heel leerzaam artikel. 2021-10-22 17:23:00  \n4                     Dank voor de uitgebreide uitleg. 2021-10-22 17:57:00  \n5    Ik heb de mods gevraagd dit topic sticky te ma... 2021-10-22 18:11:00  \n..                                                 ...                 ...  \n120  Het gaat fout bij woningcorporaties en private... 2023-02-16 19:30:00  \n121  Onderbouw je stelling eens? En maak â€˜m eens co... 2023-02-16 19:52:00  \n122  Bezorgde burger weet blijkbaar hoe een opname ... 2023-02-16 21:23:00  \n123  @jurrien Wat vroeg jij nu werkelijk toe aan in... 2023-02-17 09:31:00  \n124  Waarom is dat relevant? Discussieer gewoon op ... 2023-02-17 09:35:00  \n\n[124 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic</th>\n      <th>content</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>De energiemarkt en salderen: hoe komt de prijs...</td>\n      <td>Goedendag,In navolging van het inmiddels geslo...</td>\n      <td>2021-10-22 14:18:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>De energiemarkt en salderen: hoe komt de prijs...</td>\n      <td>3.U verbruikt en produceert stroomDezelfde pri...</td>\n      <td>2021-10-22 14:52:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>De energiemarkt en salderen: hoe komt de prijs...</td>\n      <td>Heel leerzaam artikel.</td>\n      <td>2021-10-22 17:23:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>De energiemarkt en salderen: hoe komt de prijs...</td>\n      <td>Dank voor de uitgebreide uitleg.</td>\n      <td>2021-10-22 17:57:00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>De energiemarkt en salderen: hoe komt de prijs...</td>\n      <td>Ik heb de mods gevraagd dit topic sticky te ma...</td>\n      <td>2021-10-22 18:11:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>Woningen met verkeerde energielabels, wie heef...</td>\n      <td>Het gaat fout bij woningcorporaties en private...</td>\n      <td>2023-02-16 19:30:00</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>Woningen met verkeerde energielabels, wie heef...</td>\n      <td>Onderbouw je stelling eens? En maak â€˜m eens co...</td>\n      <td>2023-02-16 19:52:00</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>Woningen met verkeerde energielabels, wie heef...</td>\n      <td>Bezorgde burger weet blijkbaar hoe een opname ...</td>\n      <td>2023-02-16 21:23:00</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>Woningen met verkeerde energielabels, wie heef...</td>\n      <td>@jurrien Wat vroeg jij nu werkelijk toe aan in...</td>\n      <td>2023-02-17 09:31:00</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>Woningen met verkeerde energielabels, wie heef...</td>\n      <td>Waarom is dat relevant? Discussieer gewoon op ...</td>\n      <td>2023-02-17 09:35:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>124 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get first ten rows within df\n",
    "topics = df_topics.head(2)\n",
    "\n",
    "\n",
    "dict_messages = {}\n",
    "message_id = 1\n",
    "\n",
    "for topic, row in topics.iterrows():\n",
    "    page_index = 0\n",
    "    while True:\n",
    "        if page_index > row['reactions']:\n",
    "            break\n",
    "        page_link = \"https://radar.avrotros.nl/forum/viewtopic.php?t=\" + row['code'] + \"&start=\" + str(page_index)\n",
    "        print(page_link)\n",
    "        page = requests.get(page_link)\n",
    "        if page.status_code != 200:\n",
    "            break\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        posts = soup.find_all('div', class_=lambda x: x and x.startswith(\"post has-profile bg\"))\n",
    "        for post in posts:\n",
    "            content = post.find(\"div\", class_=\"content\")\n",
    "            # Remove blockquotes to prevent double counting\n",
    "            for blockquote in content.find_all(\"blockquote\"):\n",
    "                blockquote.decompose()\n",
    "            content = content.text\n",
    "\n",
    "            date = post.find('p', class_=\"author\").find('time').text\n",
    "\n",
    "            dict_messages[message_id] = topic, content, date\n",
    "            message_id += 1\n",
    "\n",
    "        page_index += 20\n",
    "\n",
    "\n",
    "df_messages = pd.DataFrame.from_dict(dict_messages, orient='index', columns=['topic', 'content', 'date'])\n",
    "\n",
    "# Removing newlines and tabs from content cells.\n",
    "df_messages['content'] = df_messages['content'].str.replace('\\n', '')\n",
    "df_messages['content'] = df_messages['content'].str.replace('\\t', '')\n",
    "\n",
    "# Convert dates to datetime\n",
    "from datetime import datetime\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, \"nl_NL\")\n",
    "\n",
    "df_messages[\"date\"] = df_messages[\"date\"].str.split(\" \").apply(lambda x: \" \".join([i.capitalize() for i in x]))\n",
    "\n",
    "print(datetime.strptime(\"22 Okt 2021 14:32\", \"%d %b %Y %H:%M\"))\n",
    "\n",
    "df_messages['date'] = df_messages['date'].apply(lambda x: datetime.strptime(x, \"%d %b %Y %H:%M\"))\n",
    "\n",
    "df_messages\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2021-10-22 14:18:00\n",
      "2\n",
      "2021-10-22 14:52:00\n",
      "3\n",
      "2021-10-22 17:23:00\n",
      "4\n",
      "2021-10-22 17:57:00\n",
      "5\n",
      "2021-10-22 18:11:00\n",
      "6\n",
      "2021-10-23 11:48:00\n",
      "7\n",
      "2021-10-27 15:17:00\n",
      "8\n",
      "2021-10-28 09:25:00\n",
      "9\n",
      "2021-10-28 12:15:00\n",
      "10\n",
      "2021-10-28 18:59:00\n",
      "11\n",
      "2021-10-28 22:34:00\n",
      "12\n",
      "2021-10-28 23:24:00\n",
      "13\n",
      "2021-10-29 02:18:00\n",
      "14\n",
      "2021-10-29 02:23:00\n",
      "15\n",
      "2021-10-29 07:43:00\n",
      "16\n",
      "2021-10-29 11:40:00\n",
      "17\n",
      "2021-10-29 12:00:00\n",
      "18\n",
      "2021-10-30 11:31:00\n",
      "19\n",
      "2021-10-30 12:47:00\n",
      "20\n",
      "2021-10-30 16:14:00\n",
      "21\n",
      "2021-10-30 17:05:00\n",
      "22\n",
      "2021-10-30 18:15:00\n",
      "23\n",
      "2021-10-30 20:11:00\n",
      "24\n",
      "2021-10-30 21:53:00\n",
      "25\n",
      "2021-10-31 11:00:00\n",
      "26\n",
      "2021-10-31 11:07:00\n",
      "27\n",
      "2021-10-31 11:13:00\n",
      "28\n",
      "2021-10-31 15:47:00\n",
      "29\n",
      "2021-10-31 17:17:00\n",
      "30\n",
      "2022-11-27 15:13:00\n",
      "31\n",
      "2022-11-27 15:18:00\n",
      "32\n",
      "2022-11-27 15:29:00\n",
      "33\n",
      "2022-12-12 23:18:00\n",
      "34\n",
      "2022-12-12 23:28:00\n",
      "35\n",
      "2022-12-13 02:35:00\n",
      "36\n",
      "2022-12-13 09:07:00\n",
      "37\n",
      "2022-12-13 09:09:00\n",
      "38\n",
      "2022-12-13 09:15:00\n",
      "39\n",
      "2022-12-13 09:22:00\n",
      "40\n",
      "2022-12-13 09:36:00\n",
      "41\n",
      "2022-12-13 09:57:00\n",
      "42\n",
      "2022-12-13 10:50:00\n",
      "43\n",
      "2022-12-13 11:40:00\n",
      "44\n",
      "2022-12-13 14:35:00\n",
      "45\n",
      "2022-12-13 15:15:00\n",
      "46\n",
      "2022-12-13 15:55:00\n",
      "47\n",
      "2022-12-13 16:03:00\n",
      "48\n",
      "2022-12-13 19:46:00\n",
      "49\n",
      "2022-12-14 20:03:00\n",
      "50\n",
      "2023-02-13 19:48:00\n",
      "51\n",
      "2023-02-13 21:27:00\n",
      "52\n",
      "2023-02-13 21:32:00\n",
      "53\n",
      "2023-02-13 22:42:00\n",
      "54\n",
      "2023-02-13 23:55:00\n",
      "55\n",
      "2023-02-14 00:20:00\n",
      "56\n",
      "2023-02-14 07:10:00\n",
      "57\n",
      "2023-02-14 09:24:00\n",
      "58\n",
      "2023-02-14 09:28:00\n",
      "59\n",
      "2023-02-14 09:29:00\n",
      "60\n",
      "2023-02-14 09:31:00\n",
      "61\n",
      "2023-02-14 09:42:00\n",
      "62\n",
      "2023-02-14 09:46:00\n",
      "63\n",
      "2023-02-14 10:35:00\n",
      "64\n",
      "2023-02-14 11:05:00\n",
      "65\n",
      "2023-02-14 11:17:00\n",
      "66\n",
      "2023-02-14 14:38:00\n",
      "67\n",
      "2023-02-14 14:45:00\n",
      "68\n",
      "2023-02-14 14:55:00\n",
      "69\n",
      "2023-02-14 15:14:00\n",
      "70\n",
      "2023-02-14 15:23:00\n",
      "71\n",
      "2023-02-14 17:27:00\n",
      "72\n",
      "2023-02-14 18:29:00\n",
      "73\n",
      "2023-02-14 19:42:00\n",
      "74\n",
      "2023-02-14 20:20:00\n",
      "75\n",
      "2023-02-14 20:36:00\n",
      "76\n",
      "2023-02-14 21:42:00\n",
      "77\n",
      "2023-02-14 21:50:00\n",
      "78\n",
      "2023-02-14 22:33:00\n",
      "79\n",
      "2023-02-14 23:05:00\n",
      "80\n",
      "2023-02-15 08:08:00\n",
      "81\n",
      "2023-02-15 08:35:00\n",
      "82\n",
      "2023-02-15 08:55:00\n",
      "83\n",
      "2023-02-15 09:07:00\n",
      "84\n",
      "2023-02-15 09:13:00\n",
      "85\n",
      "2023-02-15 10:30:00\n",
      "86\n",
      "2023-02-15 11:20:00\n",
      "87\n",
      "2023-02-15 11:31:00\n",
      "88\n",
      "2023-02-15 11:36:00\n",
      "89\n",
      "2023-02-15 11:59:00\n",
      "90\n",
      "2023-02-15 12:15:00\n",
      "91\n",
      "2023-02-15 12:20:00\n",
      "92\n",
      "2023-02-15 12:21:00\n",
      "93\n",
      "2023-02-15 12:22:00\n",
      "94\n",
      "2023-02-15 12:27:00\n",
      "95\n",
      "2023-02-15 12:29:00\n",
      "96\n",
      "2023-02-15 12:31:00\n",
      "97\n",
      "2023-02-15 12:45:00\n",
      "98\n",
      "2023-02-15 13:06:00\n",
      "99\n",
      "2023-02-15 13:21:00\n",
      "100\n",
      "2023-02-15 13:25:00\n",
      "101\n",
      "2023-02-15 13:30:00\n",
      "102\n",
      "2023-02-15 13:33:00\n",
      "103\n",
      "2023-02-15 13:33:00\n",
      "104\n",
      "2023-02-15 13:42:00\n",
      "105\n",
      "2023-02-15 14:46:00\n",
      "106\n",
      "2023-02-15 15:14:00\n",
      "107\n",
      "2023-02-15 15:24:00\n",
      "108\n",
      "2023-02-15 17:05:00\n",
      "109\n",
      "2023-02-15 18:13:00\n",
      "110\n",
      "2023-02-15 18:16:00\n",
      "111\n",
      "2023-02-15 19:00:00\n",
      "112\n",
      "2023-02-15 19:12:00\n",
      "113\n",
      "2023-02-15 19:56:00\n",
      "114\n",
      "2023-02-16 01:52:00\n",
      "115\n",
      "2023-02-16 08:57:00\n",
      "116\n",
      "2023-02-16 12:54:00\n",
      "117\n",
      "2023-02-16 13:46:00\n",
      "118\n",
      "2023-02-16 14:06:00\n",
      "119\n",
      "2023-02-16 14:37:00\n",
      "120\n",
      "2023-02-16 19:30:00\n",
      "121\n",
      "2023-02-16 19:52:00\n",
      "122\n",
      "2023-02-16 21:23:00\n",
      "123\n",
      "2023-02-17 09:31:00\n",
      "124\n",
      "2023-02-17 09:35:00\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_messages.iterrows():\n",
    "    print(index)\n",
    "    print(row['date'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noudy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:146: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
      "  t = torch.tensor([], dtype=storage.dtype, device=storage.untyped().device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobBERT model loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForTokenClassification\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('pdelobelle/robbert-v2-dutch-ner')\n",
    "model = RobertaForTokenClassification.from_pretrained('pdelobelle/robbert-v2-dutch-ner', return_dict=True)\n",
    "model.eval()\n",
    "print(\"RobBERT model loaded\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "\ttensor([[    0,  6079,   499,    38,     5, 13292,    11,  6422,     8,  7010,\n",
      "             9,  2617,     4,     2,     1],\n",
      "        [    0, 25907,   129,  1283,     8,  3971,   113,    28,   118,    71,\n",
      "           435,    38, 27600,     4,     2],\n",
      "        [    0,  9396,    89,     9,   797,  2877,    22,    11,     5,  4290,\n",
      "           445,     4,     2,     1,     1],\n",
      "        [    0,  7751,     6,    74,   458,    12,  3663, 14334,   342,     4,\n",
      "             2,     1,     1,     1,     1]])\n",
      "attention_mask:\n",
      "\ttensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])\n",
      "Tokens:\n",
      "\t['<s>', 'Jan', 'Ä ging', 'Ä naar', 'Ä de', 'Ä bakker', 'Ä in', 'Ä Leuven', 'Ä en', 'Ä kocht', 'Ä een', 'Ä brood', '.', '</s>', '<pad>']\n",
      "\t['<s>', 'Bedrijven', 'Ä zoals', 'Ä Google', 'Ä en', 'Ä Microsoft', 'Ä doen', 'Ä ook', 'Ä heel', 'Ä veel', 'Ä onderzoek', 'Ä naar', 'Ä NLP', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.batch_encode_plus(\n",
    "    [\"Jan ging naar de bakker in Leuven en kocht een brood.\",\n",
    "     \"Bedrijven zoals Google en Microsoft doen ook heel veel onderzoek naar NLP.\",\n",
    "     \"Men moet een gegeven paard niet in de bek kijken.\",\n",
    "     \"Hallo, mijn naam is RobBERT.\"],\n",
    "    return_tensors=\"pt\", padding=True)\n",
    "for key, value in inputs.items():\n",
    "    print(\"{}:\\n\\t{}\".format(key, value))\n",
    "print(\"Tokens:\\n\\t{}\".format(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]) ))\n",
    "print(\"\\t{}\".format(tokenizer.convert_ids_to_tokens(inputs['input_ids'][1]) ))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'B-PER', 1: 'B-ORG', 2: 'B-LOC', 3: 'B-MISC', 4: 'I-PER', 5: 'I-ORG', 6: 'I-LOC', 7: 'I-MISC', 8: 'O'}\n"
     ]
    }
   ],
   "source": [
    "print(model.config.id2label)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0\n",
      "<s>         Jan         Ä ging       Ä naar       Ä de         Ä bakker     Ä in         Ä Leuven     Ä en         Ä kocht      Ä een        Ä brood      .           </s>        <pad>       \n",
      "\n",
      "O           B-PER       O           O           O           O           O           B-LOC       O           O           O           O           O           O           O           \n",
      "\n",
      "Sentence 1\n",
      "<s>         Bedrijven   Ä zoals      Ä Google     Ä en         Ä Microsoft  Ä doen       Ä ook        Ä heel       Ä veel       Ä onderzoek  Ä naar       Ä NLP        .           </s>        \n",
      "\n",
      "O           O           O           B-ORG       O           B-ORG       O           O           O           O           O           O           B-MISC      O           O           \n",
      "\n",
      "Sentence 2\n",
      "<s>         Men         Ä moet       Ä een        Ä gegeven    Ä paard      Ä niet       Ä in         Ä de         Ä bek        Ä kijken     .           </s>        <pad>       <pad>       \n",
      "\n",
      "O           O           O           O           O           O           O           O           O           O           O           O           O           O           O           \n",
      "\n",
      "Sentence 3\n",
      "<s>         Hallo       ,           Ä mijn       Ä naam       Ä is         Ä Rob        BER         T           .           </s>        <pad>       <pad>       <pad>       <pad>       \n",
      "\n",
      "O           O           O           O           O           O           B-PER       I-PER       I-PER       O           O           I-PER       I-PER       I-PER       I-PER       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    results = model(**inputs)\n",
    "    for i, input in enumerate(inputs['input_ids']):\n",
    "        print(f\"Sentence {i}\")\n",
    "        [print(\"{:12}\".format(token), end=\"\") for token in tokenizer.convert_ids_to_tokens(input) ]\n",
    "        print('\\n')\n",
    "        [print(\"{:12}\".format(model.config.id2label[item.item()]), end=\"\") for item in results.logits[i].argmax(axis=1)]\n",
    "        print('\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' Google', 'B-ORG'), (' Microsoft', 'B-ORG'), (' NLP', 'B-MISC')]\n"
     ]
    }
   ],
   "source": [
    "def list_of_entities(content):\n",
    "    entities = []\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        [content],\n",
    "        return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        results = model(**inputs)\n",
    "        for i, input in enumerate(inputs['input_ids']):\n",
    "            tokens = tokenizer.convert_ids_to_tokens(input)\n",
    "            labels = [model.config.id2label[item.item()] for item in results.logits[i].argmax(axis=1)]\n",
    "            for token, label in zip(tokens, labels):\n",
    "                converted_token = tokenizer.convert_tokens_to_string(token)\n",
    "                if converted_token != '<s>' and converted_token != '</s>':\n",
    "                    # If label is not O, print token and label\n",
    "                    if label != 'O':\n",
    "                        entities.append((converted_token, label))\n",
    "\n",
    "    return entities\n",
    "\n",
    "print(list_of_entities(\"Bedrijven zoals Google en Microsoft doen ook heel veel onderzoek naar NLP.\"))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (598) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 598].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_messages[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mentities\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf_messages\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlist_of_entities\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m df_messages\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2022.1\\projects\\workspace\\venv\\lib\\site-packages\\pandas\\core\\series.py:4433\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4323\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4324\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4325\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4328\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4329\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4330\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4331\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4332\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4431\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4432\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2022.1\\projects\\workspace\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1088\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1084\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m   1085\u001B[0m     \u001B[38;5;66;03m# if we are a string, try to dispatch\u001B[39;00m\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m-> 1088\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2022.1\\projects\\workspace\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1143\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1137\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m   1138\u001B[0m         \u001B[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001B[39;00m\n\u001B[0;32m   1139\u001B[0m         \u001B[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001B[39;00m\n\u001B[0;32m   1140\u001B[0m         \u001B[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001B[39;00m\n\u001B[0;32m   1141\u001B[0m         \u001B[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001B[39;00m\n\u001B[0;32m   1142\u001B[0m         \u001B[38;5;66;03m# \"Callable[[Any], Any]\"\u001B[39;00m\n\u001B[1;32m-> 1143\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1144\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1145\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m   1146\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1147\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1150\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1151\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2022.1\\projects\\workspace\\venv\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_messages[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mentities\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_messages[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m2\u001B[39m:]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mlist_of_entities\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      3\u001B[0m df_messages\n",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36mlist_of_entities\u001B[1;34m(content)\u001B[0m\n\u001B[0;32m      3\u001B[0m inputs \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_encode_plus(\n\u001B[0;32m      4\u001B[0m     [content],\n\u001B[0;32m      5\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m----> 7\u001B[0m     results \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, \u001B[38;5;28minput\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(inputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[0;32m      9\u001B[0m         tokens \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mconvert_ids_to_tokens(\u001B[38;5;28minput\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2022.1\\projects\\workspace\\venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1404\u001B[0m, in \u001B[0;36mRobertaForTokenClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1398\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1399\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1400\u001B[0m \u001B[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001B[39;00m\n\u001B[0;32m   1401\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1402\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1404\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroberta\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1405\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1410\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1411\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1412\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1414\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1416\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1418\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(sequence_output)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2022.1\\projects\\workspace\\venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:817\u001B[0m, in \u001B[0;36mRobertaModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    815\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    816\u001B[0m     buffered_token_type_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings\u001B[38;5;241m.\u001B[39mtoken_type_ids[:, :seq_length]\n\u001B[1;32m--> 817\u001B[0m     buffered_token_type_ids_expanded \u001B[38;5;241m=\u001B[39m \u001B[43mbuffered_token_type_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseq_length\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    818\u001B[0m     token_type_ids \u001B[38;5;241m=\u001B[39m buffered_token_type_ids_expanded\n\u001B[0;32m    819\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The expanded size of the tensor (598) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 598].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
